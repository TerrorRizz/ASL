{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e1dd12-2084-4fbe-83b8-cfd5e8873588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Do this the first time only to install dependencies\n",
    "!pip install tensorflow opencv-python scikit-learn numpy mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f14a76-8636-47a5-b043-6558fb7b5f90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T17:08:08.398129Z",
     "start_time": "2023-11-26T17:07:56.360662900Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682c14de-0d9a-451b-a04d-c8f75e80d8a8",
   "metadata": {},
   "source": [
    "## Initializing Detection Model and Drawing Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4579c3-5716-4b1e-8cfd-044ffcf18b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f08a7ff-093a-4624-93e8-9a4b0edef064",
   "metadata": {},
   "source": [
    "## Defining detection model and drawing tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b54e0f-23e2-4203-b23c-d199084f22b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619a0e38-4b5a-461c-b482-7b2cfecfc0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac73d510-b9af-4322-9458-09a47088f061",
   "metadata": {},
   "source": [
    "## Execution Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16386cde-38f9-44cd-a7db-eb78cd939f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "    \n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        draw_landmarks(image, results)\n",
    "        \n",
    "        cv2.imshow(\"OpenCV Feed\", image)\n",
    "        \n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621554e7-3560-466a-92e3-aa967c99925d",
   "metadata": {},
   "source": [
    "## Extracting keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931f5248-262e-49dc-b70a-c5b0d3e150e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6\n",
    "def extract_keypoints(results):\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21 * 3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21 * 3)\n",
    "    return np.concatenate([lh, rh])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1eee16-d3f0-449e-a18a-96b71760fbe9",
   "metadata": {},
   "source": [
    "## Directories for collecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e9e579-9169-4b99-95e9-81ca52e33f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7\n",
    "data_dir = os.path.join('data')\n",
    "\n",
    "# J and Z are not includede (motion based alphabets)\n",
    "letters = np.array(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'])  \n",
    "no_sequences = 25                   # (25 lh, 25rh) = total(50)\n",
    "sequence_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56598ddd-9f8d-4289-b307-2f6eb1ffdcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for letter in letters:\n",
    "    # for sequence in range(25, 50):   [use this for the first half of the data(eg: left hand[25] then right hand[25])]\n",
    "    for sequence in range(0, 25):\n",
    "        try:\n",
    "            os.makedirs(os.path.join(data_dir, letter, str(sequence)))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c1611b-a024-4644-bbaf-1e7bff8b6f6e",
   "metadata": {},
   "source": [
    "## Collecting data from the webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e90c1db-3cf9-4755-bcf4-af94a33f2112",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    for letter in letters:\n",
    "        flag = True\n",
    "        # for sequence in range(0, 24):      [use this for the first hand keypoints]\n",
    "        for sequence in range(0, 25):\n",
    "            for frame_number in range(sequence_length):\n",
    "                ret, frame = cap.read()\n",
    "            \n",
    "                image, results = mediapipe_detection(frame, holistic)\n",
    "                draw_landmarks(image, results)\n",
    "                \n",
    "                if frame_number == 0:\n",
    "                    while(flag):\n",
    "                        cv2.putText(image, 'START Collection for letter \\'{}\\', press S.'.format(letter), (120, 200), \n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 1,(0, 255, 0), 1, cv2.LINE_AA)\n",
    "                        cv2.imshow(\"OpenCV Feed\", image)\n",
    "                        if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "                            flag = False\n",
    "                    cv2.putText(image, 'Collecting for letter \\'{}\\' video number {}'.format(letter, sequence), (120, 200), \n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 1,(0, 255, 0), 1, cv2.LINE_AA)\n",
    "                else:\n",
    "                    cv2.putText(image, 'Collecting for letter \\'{}\\' video number {}'.format(letter, sequence), (120, 200), \n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 1,(0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "                keypoints = extract_keypoints(results)\n",
    "                np_path = os.path.join(data_dir, letter, str(sequence), str(frame_number))\n",
    "                np.save(np_path, keypoints)\n",
    "                \n",
    "                cv2.imshow(\"OpenCV Feed\", image)\n",
    "                \n",
    "                \n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674b46c5-c8ba-4398-9777-7c964ff12c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db44758-ad8b-493e-9149-16982c929647",
   "metadata": {},
   "source": [
    "## Preprocess the collected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc137c93-1f90-41c1-8261-3caff919a094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7bc79e-c0d6-42f9-b2ff-ab48ac06d5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label: num for num, label in enumerate(letters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da96870-30e6-44e2-96ee-e3dcef36094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "for letter in letters:\n",
    "    for sequence in range(no_sequences):\n",
    "        window = []\n",
    "        for frame_number in range(sequence_length):\n",
    "            res = np.load(os.path.join(data_dir, letter, str(sequence), '{}.npy'.format(frame_number)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[letter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dec8aa-d0be-4a8d-9f17-5841901ffdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(sequences).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4877f151-113d-4380-936f-d1b60c0ee03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f600157-6c7f-412d-ad24-f1485a27ab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ef53a5-fbd1-4b6c-aa2e-fafa4422e8be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = to_categorical(labels).astype(int)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5151d87-e679-428a-ab73-91efb4897bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e7ad3b-ccf7-4976-abed-6a8f3164e605",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d248051-22e1-4da8-98f3-e50b09b42c74",
   "metadata": {},
   "source": [
    "## Build and Train LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7251135-3cbb-4f22-800b-1f7eb4af0e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82199d33-ff12-47fc-b090-d557439c905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9\n",
    "log_dir = os.path.join('logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff974e2-03b6-44cc-8d47-c843f2bb4e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(10, 126)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(letters.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5708cd9f-f313-4817-8fe1-092850e76878",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f22bea-50d3-404f-aaec-51dc9ecd117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882084ba-f917-4adf-b1ea-38c2870e40d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12\n",
    "model.load_weights(\"asl.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236e403f-83f3-422a-82ab-3478ebe77a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=2000, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ea4b12-201d-4386-beb4-881c882abab5",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc00d47f-3a04-4a9d-9efc-5c70198742f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a28a4a-ad17-458b-88ca-81591627188e",
   "metadata": {},
   "outputs": [],
   "source": [
    "letters[np.argmax(res[29])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1a2a15-c059-440d-b282-ef1ace586bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "letters[np.argmax(y_test[29])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e3f33f-2d1d-4a1b-a917-8b9e7636df15",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(res[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e018cd-1cf2-46eb-ba8d-b394722729ff",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4847bfc9-12a8-47fd-9c7e-b4494733910f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('asl.h5')\n",
    "model.save('asl.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2385eb4e-83da-4407-94ce-6a348f060586",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcee53c-19af-413b-9fe5-881eab44795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9993db34-7c9a-4bee-b18b-baf98702cae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d4c6c5-25b2-4c08-a815-ffea3041dc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9860c02-64c7-4441-9ff6-1a3b542a6d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdafde5b-9e2d-4fb8-9b8a-bb71dcb3c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543ebadc-051c-4e0d-bf81-5179485b23af",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9146fba4-9a5d-4c66-abe1-8fa9c67ce87d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 13 Main execution part\n",
    "\n",
    "predictions = []\n",
    "sequence = []\n",
    "sentence = []\n",
    "threshold = 0.8\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "    \n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        draw_landmarks(image, results)\n",
    "\n",
    "        keypoints = extract_keypoints(results)\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-10:]\n",
    "\n",
    "        if len(sequence) == 10:\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            print(letters[np.argmax(res)])\n",
    "            predictions.append(np.argmax(res))\n",
    "\n",
    "            if np.unique(predictions[-10:])[0] == np.argmax(res):\n",
    "                if res[np.argmax(res)] > threshold:\n",
    "                    letter = letters[np.argmax(res)]\n",
    "                else:\n",
    "                    letter = 'no input'\n",
    "\n",
    "        cv2.rectangle(image, (0, 0), (640, 40), (245, 117, 16), -1)\n",
    "        cv2.putText(image, letter, (3, 30), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        cv2.imshow(\"ASL Recognition\", image)\n",
    "        \n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d74fff9-7c8a-4fbe-80ed-2ee2f4237a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 14 --- Use this in case webcam is still running after closing the program \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
